{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries and Using Kaggle API to access datasets"
      ],
      "metadata": {
        "id": "2P2SfdcqSfHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsiqDo89nTzX",
        "outputId": "ca870c52-eb97-4ca4-cd5f-65e00bb96703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhUrHudTqVMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd4916f-9dd0-416e-b9ae-651988a09ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_Le2ooDqZEZ"
      },
      "outputs": [],
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU44CtWZqf0H",
        "outputId": "df348877-43a6-4556-e2f8-36d76210c4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading multilingual-sentiment-analysis.zip to /content\n",
            " 99% 1.80G/1.81G [00:20<00:00, 131MB/s]\n",
            "100% 1.81G/1.81G [00:20<00:00, 96.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d samanazhar/multilingual-sentiment-analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPCT4txqj0s",
        "outputId": "0fa3c4cd-ede7-4f80-96f7-494c7818738a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/multilingual-sentiment-analysis.zip\n",
            "  inflating: PMLN_predicted_tweets.csv  \n",
            "  inflating: PPP_predicted_tweets.csv  \n",
            "  inflating: PTI_predicted_tweets.csv  \n",
            "  inflating: Scraped_Tweets/PMLN_Complete_Dataset.csv  \n",
            "  inflating: Scraped_Tweets/PPP_Complete_Dataset.csv  \n",
            "  inflating: Scraped_Tweets/PTI_Complete_Dataset.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/multilingual-sentiment-analysis.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import datasets\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import re"
      ],
      "metadata": {
        "id": "TzZ59t3DqA0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=pd.read_csv('/content/PMLN_predicted_tweets.csv')\n",
        "ds1=pd.read_csv('/content/PPP_predicted_tweets.csv')\n",
        "ds2=pd.read_csv('/content/PTI_predicted_tweets.csv')"
      ],
      "metadata": {
        "id": "WEQVQ6PUqMCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=ds[ds['language']=='in']\n",
        "ds1=ds1[ds1['language']=='in']\n",
        "ds2=ds2[ds2['language']=='in']"
      ],
      "metadata": {
        "id": "CmVTLzK1qjq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Data"
      ],
      "metadata": {
        "id": "j2x0R6BWSjwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds=ds.dropna()\n",
        "ds1=ds1.dropna()\n",
        "ds2=ds2.dropna()\n",
        "ds1 = ds1.drop(ds1[ds1['preprocessed_tweet'].apply(lambda x: isinstance(x, float))].index)\n",
        "ds1 = ds.drop(ds[ds['preprocessed_tweet'].apply(lambda x: isinstance(x, float))].index)\n",
        "ds1 = ds2.drop(ds2[ds2['preprocessed_tweet'].apply(lambda x: isinstance(x, float))].index)\n",
        "ds.reset_index(drop=True, inplace=True)\n",
        "ds1.reset_index(drop=True, inplace=True)\n",
        "ds2.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "TkBXrhdeqkxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.concat([ds['preprocessed_tweet'], ds1['preprocessed_tweet'],ds2['preprocessed_tweet']], ignore_index=True)\n",
        "y= pd.concat([ds['sentiment'], ds1['sentiment'],ds2['sentiment']], ignore_index=True)\n",
        "dataset = list(zip(X, y))\n",
        "X, y = zip(*dataset)"
      ],
      "metadata": {
        "id": "FIyMv_hkqmIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10,shuffle=True)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=21,shuffle=True)"
      ],
      "metadata": {
        "id": "9fQPUWbcqnLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(ds):\n",
        "    corpus = []\n",
        "    for i in range(len(ds)):\n",
        "        if isinstance(ds[i], str):\n",
        "            review = re.sub('[^a-zA-Z]', ' ', ds[i])\n",
        "            review = review.split(' ')\n",
        "            review = [word for word in review if word != '']\n",
        "            corpus.append(review)\n",
        "    return corpus\n"
      ],
      "metadata": {
        "id": "_uKb2lyKqoMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=pre_process(x_train)\n",
        "x_val=pre_process(x_val)\n",
        "x_test=pre_process(x_test)\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_val = tokenizer.texts_to_sequences(x_val)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "max_len=len(max(X,key=len))\n",
        "x_train=pad_sequences(x_train, maxlen=max_len, padding='post', truncating='post')\n",
        "x_test=pad_sequences(x_test, maxlen=max_len, padding='post', truncating='post')\n",
        "x_val=pad_sequences(x_val, maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "o-XJXSTJqpVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=tokenizer.word_index"
      ],
      "metadata": {
        "id": "wQbPkxVwqq08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN with Bi-LSTM Model"
      ],
      "metadata": {
        "id": "UZkCpDKzSmFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentiment_analysis_model(vocab_size, embedding_dim, maxlen):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Bidirectional(layers.LSTM(12,return_sequences=False)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "vocab_size=87554\n",
        "embedding_dim = 12\n",
        "maxlen = max_len\n",
        "\n",
        "model = create_sentiment_analysis_model(vocab_size, embedding_dim, maxlen)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drUciO73qseQ",
        "outputId": "c194a758-7a86-4c8e-d21c-e7bb98d4f704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 279, 12)           1050648   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 279, 12)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 24)                2400      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                1600      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1054713 (4.02 MB)\n",
            "Trainable params: 1054713 (4.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "model.fit(\n",
        "    x_train,tensorflow.constant(y_train),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val,tensorflow.constant(y_val)),callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVDxVGy8rWP2",
        "outputId": "8df7088c-aa1a-431c-c57f-c9588585ff3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1704/1704 [==============================] - 128s 73ms/step - loss: 0.3352 - accuracy: 0.8533 - val_loss: 0.1730 - val_accuracy: 0.9349\n",
            "Epoch 2/20\n",
            "1704/1704 [==============================] - 46s 27ms/step - loss: 0.1689 - accuracy: 0.9374 - val_loss: 0.1309 - val_accuracy: 0.9511\n",
            "Epoch 3/20\n",
            "1704/1704 [==============================] - 42s 25ms/step - loss: 0.1186 - accuracy: 0.9558 - val_loss: 0.1235 - val_accuracy: 0.9553\n",
            "Epoch 4/20\n",
            "1704/1704 [==============================] - 60s 36ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.1231 - val_accuracy: 0.9558\n",
            "Epoch 5/20\n",
            "1704/1704 [==============================] - 40s 24ms/step - loss: 0.0817 - accuracy: 0.9703 - val_loss: 0.1333 - val_accuracy: 0.9569\n",
            "Epoch 6/20\n",
            "1704/1704 [==============================] - 41s 24ms/step - loss: 0.0724 - accuracy: 0.9738 - val_loss: 0.1393 - val_accuracy: 0.9558\n",
            "Epoch 7/20\n",
            "1704/1704 [==============================] - 40s 24ms/step - loss: 0.0670 - accuracy: 0.9759 - val_loss: 0.1501 - val_accuracy: 0.9554\n",
            "Epoch 8/20\n",
            "1704/1704 [==============================] - 51s 30ms/step - loss: 0.0611 - accuracy: 0.9780 - val_loss: 0.1475 - val_accuracy: 0.9564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7945089da800>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,tensorflow.constant(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8DjAxMrY7X",
        "outputId": "0011d8e3-15ff-494e-931b-38d3a6dc554d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "474/474 [==============================] - 5s 11ms/step - loss: 0.1465 - accuracy: 0.9587\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14652438461780548, 0.9587349891662598]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=[\"ghatiya insaan ho tum!!\"]\n",
        "sentence=pre_process(sentence)\n",
        "sentence = tokenizer.texts_to_sequences(sentence)\n",
        "sentence=pad_sequences(sentence, maxlen=max_len, padding='post', truncating='post')\n",
        "output=model.predict(sentence)\n",
        "threshold = 0.5\n",
        "prediction = 1 if output > threshold else 0\n",
        "print(\"Sentiment for this tweet is:\",prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKfCawQNraTQ",
        "outputId": "2b0691db-9136-4c5b-9d6d-05aedc1a00bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Sentiment for this tweet is: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=[\"i will vote for you!\"]\n",
        "sentence=pre_process(sentence)\n",
        "sentence = tokenizer.texts_to_sequences(sentence)\n",
        "sentence=pad_sequences(sentence, maxlen=max_len, padding='post', truncating='post')\n",
        "output=model.predict(sentence)\n",
        "threshold = 0.5\n",
        "prediction = 1 if output > threshold else 0\n",
        "print(\"Sentiment for this tweet is:\",prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJWU6_w-tr_B",
        "outputId": "aa52178c-9454-416b-bfe0-e0925c4ffa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "Sentiment for this tweet is: 0\n"
          ]
        }
      ]
    }
  ]
}
